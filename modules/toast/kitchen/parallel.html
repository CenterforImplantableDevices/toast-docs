<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>toast.kitchen.parallel &mdash; toast 1.3.2 documentation</title>
      <link rel="stylesheet" href="../../../static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../" id="documentation_options" src="../../../static/documentation_options.js"></script>
        <script src="../../../static/jquery.js"></script>
        <script src="../../../static/underscore.js"></script>
        <script src="../../../static/doctools.js"></script>
    <script src="../../../static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../toast.html" class="icon icon-home"> toast
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../toast.bread.html">toast.bread</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../toast.butter.html">toast.butter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../toast.heat.html">toast.heat</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../toast.kitchen.html">toast.kitchen</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../toast.misc.html">toast.misc</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../toast.plate.html">toast.plate</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../toast.html">toast</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../toast.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../../index.html">Module code</a> &raquo;</li>
      <li>toast.kitchen.parallel</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for toast.kitchen.parallel</h1><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">torch.multiprocessing</span> <span class="kn">import</span> <span class="n">Process</span><span class="p">,</span> <span class="n">Pool</span><span class="p">,</span> <span class="n">Manager</span><span class="p">,</span> <span class="n">current_process</span>
<span class="kn">from</span> <span class="nn">toast.kitchen.tracker</span> <span class="kn">import</span> <span class="n">update_process_tracker</span>
<span class="kn">from</span> <span class="nn">toast.kitchen</span> <span class="kn">import</span> <span class="n">terminate</span> <span class="k">as</span> <span class="n">tterm</span>
<span class="kn">from</span> <span class="nn">toast.misc</span> <span class="kn">import</span> <span class="n">tlog</span>
<span class="kn">from</span> <span class="nn">copy</span> <span class="kn">import</span> <span class="n">deepcopy</span>
<span class="kn">import</span> <span class="nn">threading</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">import</span> <span class="nn">queue</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">gc</span>
<span class="kn">import</span> <span class="nn">os</span>



<span class="n">torch</span><span class="o">.</span><span class="n">multiprocessing</span><span class="o">.</span><span class="n">set_start_method</span><span class="p">(</span> <span class="s1">&#39;spawn&#39;</span><span class="p">,</span> <span class="n">force</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<div class="viewcode-block" id="run_parallel"><a class="viewcode-back" href="../../../toast.kitchen.parallel.html#toast.kitchen.parallel.run_parallel">[docs]</a><span class="k">def</span> <span class="nf">run_parallel</span><span class="p">(</span> <span class="n">target_fcn</span><span class="p">,</span> <span class="n">fcn_args</span><span class="p">,</span> <span class="n">test_args</span><span class="p">,</span> <span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_job_gpu</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_job_sys</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_mem_gpu</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_mem_sys</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">percent_gpu</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">percent_memory</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">still_test</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">gpu_test_index</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">cache_results</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">path_cache_results</span><span class="o">=</span><span class="s1">&#39;./&#39;</span><span class="p">,</span> <span class="n">path_log_file</span><span class="o">=</span><span class="s1">&#39;./&#39;</span><span class="p">,</span> <span class="n">find_newLimits</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">run_comment</span><span class="o">=</span><span class="s1">&#39;run_parallel&#39;</span><span class="p">,</span> <span class="n">update_processTracker</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;Execute multiple runs of ``target_fcn`` in parallel asynchronously.</span>

<span class="sd">    This function will find the memory and cpu limitaitons of the machine it is running on, and automatically run as many parallel operations as is safely possible.</span>

<span class="sd">    This function will limit each parallel execution to one process and one thread (via `torch.set_num_threads&lt;https://pytorch.org/docs/stable/generated/torch.set_num_threads.html#torch.set_num_threads&gt;`, </span>
<span class="sd">    to avoid overallocation of CPU cores. Overallocation of CPU resources will slow execution dramatically.</span>

<span class="sd">    Important:</span>

<span class="sd">        The returned results are not necessarily in the same order, as the parallel execution is asynchronous.</span>

<span class="sd">    Args:</span>
<span class="sd">        target_fcn (function pointer):          The funciton to run in parallel</span>
<span class="sd">        fcn_args (2D list):                     A list of lists of arguments to be passed to the function to test. Each entry in the outer list will be passed to the target_fcn</span>
<span class="sd">        test_args (list):                       A list of arguments (single instance) to be passed to the function to test</span>
<span class="sd">        use_gpu (bool, optional):               Whether to use any available GPUs</span>
<span class="sd">        max_job_gpu (int, optional):            Maximum number of jobs to run on each GPU</span>
<span class="sd">        max_job_sys (int, optional):            Maximum number of jobs to run on the entire system</span>
<span class="sd">        max_mem_gpu (int, optional):            Maximum bytes of memory to use on each GPU</span>
<span class="sd">        max_mem_sys (int, optional):            Maximum bytes of memory to use on the entire system</span>
<span class="sd">        percent_gpu (float, optional):          Decimal value signifying what percentage of GPU memory to use</span>
<span class="sd">        percent_memory (float, optional):       Decimal value signifying what percentage of system memory to use</span>
<span class="sd">        still_test (bool, optional):            Whether to still perform a test run. If a smaller limit is found than what is input, the smaller limit will be used.</span>
<span class="sd">        gpu_test_index (int, optional):         CUDA device index to use when testing GPU memory consumption</span>
<span class="sd">        cache_results (bool, optional):         Wether to cache results in files on the disk rather than saving them in memory. Use if returned values take up excessive memory and cannot all be stored while processes are still running.</span>
<span class="sd">        path_cache_results (str, optional):     Path to a folder to cache returned values from each process.</span>
<span class="sd">        path_log_file (str, optional):          Path to the log file for logging activity</span>
<span class="sd">        find_newLimits (bool, optional):        Whether to perform a test run of the passed fuction to find new machine limits.</span>
<span class="sd">        run_comment (str, optional):            Comment to label the parallel processes as when tracking</span>
<span class="sd">        update_processTracker (bool, optional): Whether to create and update a process tracker file in a `.toast-trackers` folder in the user&#39;s home directory</span>

<span class="sd">    Returns:</span>
<span class="sd">        results (list, contains all of the output s of the parallel runs.  These outputs are not necessarily in the order they were passed)</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="c1"># Set the maximum limits for parallelization on this machine.</span>
    <span class="k">if</span> <span class="n">find_newLimits</span><span class="p">:</span>
        <span class="n">num_gpu</span><span class="p">,</span> <span class="n">num_jobs</span><span class="p">,</span> <span class="n">max_jobs</span> <span class="o">=</span> <span class="n">get_memory_limits</span><span class="p">(</span> <span class="n">target_fcn</span><span class="p">,</span> <span class="n">test_args</span><span class="p">,</span> <span class="n">use_gpu</span><span class="o">=</span><span class="n">use_gpu</span><span class="p">,</span> <span class="n">max_job_gpu</span><span class="o">=</span><span class="n">max_job_gpu</span><span class="p">,</span> <span class="n">max_job_sys</span><span class="o">=</span><span class="n">max_job_sys</span><span class="p">,</span> <span class="n">max_mem_gpu</span><span class="o">=</span><span class="n">max_mem_gpu</span><span class="p">,</span> <span class="n">max_mem_sys</span><span class="o">=</span><span class="n">max_mem_sys</span><span class="p">,</span> <span class="n">percent_gpu</span><span class="o">=</span><span class="n">percent_gpu</span><span class="p">,</span> <span class="n">percent_memory</span><span class="o">=</span><span class="n">percent_memory</span><span class="p">,</span> <span class="n">still_test</span><span class="o">=</span><span class="n">still_test</span><span class="p">,</span> <span class="n">gpu_test_index</span><span class="o">=</span><span class="n">gpu_test_index</span><span class="p">,</span> <span class="n">path_log_file</span><span class="o">=</span><span class="n">path_log_file</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">num_gpu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span><span class="p">()</span>
        <span class="n">num_jobs</span> <span class="o">=</span> <span class="n">max_job_gpu</span>
        <span class="n">max_jobs</span> <span class="o">=</span> <span class="n">max_job_sys</span>

    <span class="n">tlog</span><span class="o">.</span><span class="n">output_log</span><span class="p">(</span><span class="s1">&#39;Number of Parallel Jobs: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span> <span class="n">max_jobs</span><span class="p">,</span> <span class="n">num_gpu</span> <span class="o">*</span> <span class="n">num_jobs</span><span class="p">)),</span> <span class="n">path_log_file</span><span class="p">)</span>

    <span class="c1"># Create output variables.</span>
    <span class="n">results</span>        <span class="o">=</span> <span class="p">[]</span>
    <span class="k">if</span> <span class="n">cache_results</span><span class="p">:</span>
        <span class="n">counter_filesOut</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># Set up queues for transfering data between threads</span>
    <span class="n">worker_manager</span>  <span class="o">=</span> <span class="n">Manager</span><span class="p">()</span>
    <span class="n">num_queued_jobs</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">fcn_args</span><span class="p">)</span>
    <span class="n">process_queue</span>   <span class="o">=</span> <span class="n">worker_manager</span><span class="o">.</span><span class="n">Queue</span><span class="p">(</span> <span class="n">num_queued_jobs</span><span class="p">)</span>
    <span class="n">results_queue</span>   <span class="o">=</span> <span class="n">worker_manager</span><span class="o">.</span><span class="n">Queue</span><span class="p">(</span> <span class="n">num_queued_jobs</span><span class="p">)</span>
    <span class="n">fcn_args_queue</span>  <span class="o">=</span> <span class="n">worker_manager</span><span class="o">.</span><span class="n">Queue</span><span class="p">(</span> <span class="n">num_queued_jobs</span><span class="p">)</span>
    <span class="n">process_queue</span><span class="o">.</span><span class="n">put</span><span class="p">(</span> <span class="p">{})</span>
    <span class="n">fcn_args_queue</span><span class="o">.</span><span class="n">put</span><span class="p">(</span> <span class="n">fcn_args</span><span class="p">)</span>

    <span class="n">jobs</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="c1"># Define the worker processes that will run training</span>
    <span class="k">with</span> <span class="n">Pool</span><span class="p">(</span><span class="n">processes</span><span class="o">=</span><span class="nb">min</span><span class="p">(</span> <span class="n">max_jobs</span><span class="p">,</span> <span class="n">num_queued_jobs</span><span class="p">))</span> <span class="k">as</span> <span class="n">workers</span><span class="p">:</span>
        <span class="c1"># Create asynchronous jobs for each training iteration, without exceeding the num_jobs nor number of jobs per gpu</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span> <span class="n">num_jobs</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">g</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span> <span class="n">num_gpu</span><span class="p">):</span>
                <span class="n">worker_args</span> <span class="o">=</span> <span class="p">[</span> <span class="n">target_fcn</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span> <span class="p">(</span><span class="s1">&#39;cuda:&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">g</span><span class="p">))</span> <span class="k">if</span> <span class="p">(</span><span class="n">use_gpu</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">())</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span><span class="p">),</span> <span class="n">fcn_args_queue</span><span class="p">,</span> <span class="n">results_queue</span><span class="p">,</span> <span class="n">process_queue</span><span class="p">]</span>
                <span class="n">workers</span><span class="o">.</span><span class="n">apply_async</span><span class="p">(</span> <span class="n">_worker_process</span><span class="p">,</span> <span class="p">[</span><span class="o">*</span><span class="n">worker_args</span><span class="p">],</span> <span class="n">error_callback</span><span class="o">=</span><span class="n">_worker_error</span><span class="p">)</span>
                <span class="n">jobs</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">if</span> <span class="n">jobs</span> <span class="o">&gt;=</span> <span class="n">max_jobs</span><span class="p">:</span>
                    <span class="k">break</span>
            <span class="k">if</span> <span class="n">jobs</span> <span class="o">&gt;=</span> <span class="n">max_jobs</span><span class="p">:</span>
                <span class="k">break</span>
        <span class="c1"># Update the process tracker to inform user of status, and get the number of processes running/finished.</span>
        <span class="k">if</span> <span class="n">update_processTracker</span><span class="p">:</span>
            <span class="n">processes_running</span> <span class="o">=</span> <span class="n">update_process_tracker</span><span class="p">(</span> <span class="n">process_queue</span><span class="p">,</span> <span class="n">run_comment</span><span class="p">)</span>
        
        <span class="c1"># Wait for the results to populate.</span>
        <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
        <span class="n">nothing_running</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">while</span><span class="p">(</span> <span class="nb">len</span><span class="p">(</span> <span class="n">results</span><span class="p">)</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span> <span class="n">fcn_args</span><span class="p">)):</span>
            <span class="c1"># Update the process tracker to inform user of status, and get the number of processes running/finished.</span>
            <span class="k">if</span> <span class="n">update_processTracker</span><span class="p">:</span>
                <span class="n">processes_running</span> <span class="o">=</span> <span class="n">update_process_tracker</span><span class="p">(</span> <span class="n">process_queue</span><span class="p">,</span> <span class="n">run_comment</span><span class="p">)</span>
            <span class="c1"># If all processes have finished, break (even if for some reason results wasn&#39;t appended)</span>
            <span class="k">if</span> <span class="n">processes_running</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">processes_running</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
                <span class="n">nothing_running</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="n">nothing_running</span> <span class="o">&gt;</span> <span class="mi">10</span><span class="p">:</span>
                <span class="k">break</span>

            <span class="c1"># Add any new results to the list of results.</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">proc_output</span> <span class="o">=</span> <span class="n">results_queue</span><span class="o">.</span><span class="n">get</span><span class="p">(</span> <span class="n">block</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">timeout</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">cache_results</span><span class="p">:</span>
                    <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span> <span class="n">proc_output</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span> <span class="n">path_cache_results</span><span class="p">,</span> <span class="s1">&#39;output_&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">counter_filesOut</span><span class="p">)</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">proc_output</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">+</span><span class="s1">&#39;.pkl&#39;</span><span class="p">),</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                        <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">proc_output</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
                    <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">counter_filesOut</span><span class="p">)</span>
                    <span class="n">counter_filesOut</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">except</span> <span class="n">queue</span><span class="o">.</span><span class="n">Empty</span><span class="p">:</span>
                <span class="k">pass</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">e</span>

            <span class="c1"># If the user creates an exit file, end the program</span>
            <span class="n">tterm</span><span class="o">.</span><span class="n">check_exit</span><span class="p">()</span>
            <span class="c1"># If the user creates a finish file, stop executing the parallel processes</span>
            <span class="k">if</span> <span class="n">tterm</span><span class="o">.</span><span class="n">check_finish</span><span class="p">():</span>
                <span class="k">break</span>
            <span class="n">gc</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
            <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>

        <span class="c1"># This is a redundancy that shouldn&#39;t be required, yet sometimes keeps items from getting stuck in the queue</span>
        <span class="n">queue_empty</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">while</span> <span class="ow">not</span> <span class="n">queue_empty</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span> <span class="n">results_queue</span><span class="o">.</span><span class="n">get</span><span class="p">(</span> <span class="n">block</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">timeout</span><span class="o">=</span><span class="mf">0.5</span><span class="p">))</span>
            <span class="k">except</span> <span class="n">queue</span><span class="o">.</span><span class="n">Empty</span><span class="p">:</span>
                <span class="n">queue_empty</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">e</span>
            <span class="k">if</span> <span class="n">tterm</span><span class="o">.</span><span class="n">check_finish</span><span class="p">():</span>
                <span class="k">break</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Closing worker processes...&#39;</span><span class="p">)</span> <span class="c1"># This is probably redundant, but I want to make extra sure they close</span>
    <span class="n">workers</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="n">workers</span><span class="o">.</span><span class="n">join</span><span class="p">()</span>
    <span class="n">tterm</span><span class="o">.</span><span class="n">clear_finish</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">results</span></div>


<div class="viewcode-block" id="get_memory_limits"><a class="viewcode-back" href="../../../toast.kitchen.parallel.html#toast.kitchen.parallel.get_memory_limits">[docs]</a><span class="k">def</span> <span class="nf">get_memory_limits</span><span class="p">(</span> <span class="n">target_fcn</span><span class="p">,</span> <span class="n">target_args</span><span class="p">,</span> <span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_job_gpu</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_job_sys</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_mem_gpu</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_mem_sys</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">percent_gpu</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">percent_memory</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">still_test</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">gpu_test_index</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">path_log_file</span><span class="o">=</span><span class="s1">&#39;./&#39;</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;This will run ``target_fcn`` with ``target_args`` arguments in an independent process while tracking CPU and GPU memory usage.</span>
<span class="sd">    After the entire function execution, it will use the maximum recorded instantaneous memory usage to calculate </span>
<span class="sd">    how many processes can safely be run in parallel without running out of memory or cpu cores.</span>

<span class="sd">    Args:</span>
<span class="sd">        target_fcn (function pointer):    The funciton to test in order to determine parallelization limits</span>
<span class="sd">        target_args (list):               A list of arguments (single instance) to be passed to the function to test</span>
<span class="sd">        use_gpu (bool, optional):         Whether to use any available GPUs</span>
<span class="sd">        max_job_gpu (int, optional):      Maximum number of jobs to run on each GPU</span>
<span class="sd">        max_job_sys (int, optional):      Maximum number of jobs to run on the entire system</span>
<span class="sd">        max_mem_gpu (int, optional):            Maximum bytes of memory to use on each GPU</span>
<span class="sd">        max_mem_sys (int, optional):            Maximum bytes of memory to use on the entire system</span>
<span class="sd">        percent_gpu (float, optional):          Decimal value signifying what percentage of GPU memory to use</span>
<span class="sd">        percent_memory (float, optional): Decimal value signifying what percentage of system memory to use</span>
<span class="sd">        still_test (bool, optional):      Whether to still perform a test run. If a smaller limit is found than what is input, the smaller limit will be used.</span>
<span class="sd">        gpu_test_index (int, optional):   CUDA device index to use when testing GPU memory consumption</span>
<span class="sd">        path_log_file (str, optional):    path to log file where runtime output can be saved</span>
<span class="sd">    Returns:</span>
<span class="sd">        num_gpu (int, number of GPU available), num_jobs (int, max number of jobs per GPU), max_jobs (int, max total number of jobs on the system)</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">if</span> <span class="n">use_gpu</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
        <span class="c1"># Test/Determine Memory Consumption on first iteration to determine how many processes we can safely run in parallel.</span>
        <span class="c1"># To skip this part, set both max_jobs_gpu and max_jobs_sys in params file to a fixed positive number.</span>
        <span class="k">if</span> <span class="p">((</span><span class="n">max_job_gpu</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">max_job_sys</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">))</span> <span class="ow">or</span> <span class="n">still_test</span><span class="p">:</span>
            <span class="c1"># Define GPU CUDA device and Bus ID</span>
            <span class="n">gpu_test_device</span>  <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda:&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">gpu_test_index</span><span class="p">))</span>
            <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;CUDA_DEVICE_ORDER&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;PCI_BUS_ID&quot;</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">gpu_bus_id</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;CUDA_VISIBLE_DEVICES&#39;</span><span class="p">][</span><span class="n">gpu_test_index</span><span class="p">])</span>
            <span class="k">except</span><span class="p">:</span>
                <span class="n">tlog</span><span class="o">.</span><span class="n">output_log</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">WARNING: &quot;CUDA_VISIBLE_DEVICES&quot; environment variable is not defined</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">path_log_file</span><span class="p">)</span>
                <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>
                <span class="n">gpu_bus_id</span> <span class="o">=</span> <span class="n">gpu_test_index</span>
            <span class="n">tlog</span><span class="o">.</span><span class="n">output_log</span><span class="p">(</span><span class="s1">&#39;gpu_test_device: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">gpu_test_device</span><span class="p">),</span> <span class="n">path_log_file</span><span class="p">)</span>
            <span class="n">tlog</span><span class="o">.</span><span class="n">output_log</span><span class="p">(</span><span class="s1">&#39;gpu_bus_id:    : &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">gpu_bus_id</span><span class="p">),</span>      <span class="n">path_log_file</span><span class="p">)</span>

            <span class="c1"># Define memory tracking variables</span>
            <span class="k">global</span>  <span class="n">used_gpu_memory</span><span class="p">,</span> <span class="n">free_gpu_memory</span><span class="p">,</span> <span class="n">used_sys_memory</span><span class="p">,</span> <span class="n">free_sys_memory</span><span class="p">,</span> <span class="n">stop_tracking</span>
            <span class="n">used_gpu_memory</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">used_sys_memory</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">free_gpu_memory</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">free_sys_memory</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">stop_tracking</span>   <span class="o">=</span> <span class="kc">False</span>
            <span class="c1"># Start memory tracking</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
            <span class="n">thread_gpu</span> <span class="o">=</span> <span class="n">threading</span><span class="o">.</span><span class="n">Thread</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="n">track_memory_usage_gpu</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">[</span><span class="n">gpu_bus_id</span><span class="p">])</span>
            <span class="n">thread_sys</span> <span class="o">=</span> <span class="n">threading</span><span class="o">.</span><span class="n">Thread</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="n">track_memory_usage_sys</span><span class="p">)</span>
            <span class="n">thread_gpu</span><span class="o">.</span><span class="n">daemon</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">thread_sys</span><span class="o">.</span><span class="n">daemon</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">thread_gpu</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
            <span class="n">thread_sys</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
            <span class="n">tlog</span><span class="o">.</span><span class="n">output_log</span><span class="p">(</span><span class="s1">&#39;Getting free_gpu_memory... &#39;</span><span class="p">,</span> <span class="n">path_log_file</span><span class="p">)</span>
            <span class="n">base_free_gpu_memory</span> <span class="o">=</span> <span class="n">free_gpu_memory</span>
            <span class="n">base_free_sys_memory</span> <span class="o">=</span> <span class="n">free_sys_memory</span>
            <span class="c1"># Wait for memory tracking to initialize</span>
            <span class="k">while</span> <span class="p">(</span><span class="n">base_free_gpu_memory</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">base_free_sys_memory</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">):</span>
                <span class="n">base_free_gpu_memory</span> <span class="o">=</span> <span class="n">free_gpu_memory</span>
                <span class="n">base_free_sys_memory</span> <span class="o">=</span> <span class="n">free_sys_memory</span>
                <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>
            <span class="n">tlog</span><span class="o">.</span><span class="n">output_log</span><span class="p">(</span><span class="s1">&#39;free_gpu_memory: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">free_gpu_memory</span><span class="o">/</span><span class="mi">1000000</span><span class="p">),</span> <span class="n">path_log_file</span><span class="p">)</span>
            <span class="n">tlog</span><span class="o">.</span><span class="n">output_log</span><span class="p">(</span><span class="s1">&#39;free_sys_memory: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">free_sys_memory</span><span class="o">/</span><span class="mi">1000000</span><span class="p">),</span> <span class="n">path_log_file</span><span class="p">)</span>

            <span class="c1"># Run GPU test</span>
            <span class="n">target_args</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">gpu_test_device</span>
            <span class="n">worker_test</span> <span class="o">=</span> <span class="n">Process</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="n">target_fcn</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">[</span><span class="o">*</span><span class="n">target_args</span><span class="p">])</span>
            <span class="n">worker_test</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
            <span class="n">worker_test</span><span class="o">.</span><span class="n">join</span><span class="p">()</span>
            <span class="n">stop_tracking</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)</span>
            <span class="c1"># Calculate number of jobs</span>
            <span class="k">if</span> <span class="n">max_mem_gpu</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">max_mem_gpu</span> <span class="o">=</span> <span class="n">base_free_gpu_memory</span> <span class="o">*</span> <span class="n">max_mem_gpu</span>
            <span class="k">elif</span> <span class="n">max_mem_gpu</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">max_mem_gpu</span> <span class="o">=</span> <span class="n">base_free_gpu_memory</span>
            <span class="k">if</span> <span class="n">max_mem_sys</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">max_mem_sys</span> <span class="o">=</span> <span class="n">base_free_sys_memory</span> <span class="o">*</span> <span class="n">max_mem_sys</span>
            <span class="k">elif</span> <span class="n">max_mem_sys</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">max_mem_sys</span> <span class="o">=</span> <span class="n">base_free_sys_memory</span>
            <span class="n">test_max_job_gpu</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span> <span class="nb">int</span><span class="p">((</span><span class="n">max_mem_gpu</span> <span class="o">*</span> <span class="mf">0.95</span><span class="p">)</span> <span class="o">/</span> <span class="n">used_gpu_memory</span><span class="p">)</span> <span class="o">*</span> <span class="n">percent_gpu</span><span class="p">)</span>
            <span class="n">test_max_job_sys</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span> <span class="nb">int</span><span class="p">((</span><span class="n">max_mem_sys</span> <span class="o">*</span> <span class="mf">0.95</span><span class="p">)</span> <span class="o">/</span> <span class="n">used_sys_memory</span><span class="p">)</span> <span class="o">*</span> <span class="n">percent_memory</span><span class="p">)</span>
            <span class="n">max_job_gpu</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span> <span class="n">max_job_gpu</span><span class="p">,</span> <span class="n">test_max_job_gpu</span><span class="p">)</span> <span class="k">if</span> <span class="n">max_job_gpu</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">test_max_job_gpu</span>
            <span class="n">max_job_sys</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span> <span class="n">max_job_sys</span><span class="p">,</span> <span class="n">test_max_job_sys</span><span class="p">)</span> <span class="k">if</span> <span class="n">max_job_sys</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">test_max_job_sys</span>
            <span class="n">tlog</span><span class="o">.</span><span class="n">output_log</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">used_gpu_memory: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">used_gpu_memory</span><span class="o">/</span><span class="mi">1000000</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;        num_jobs_gpu: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">max_job_gpu</span><span class="p">),</span> <span class="n">path_log_file</span><span class="p">)</span>
            <span class="n">tlog</span><span class="o">.</span><span class="n">output_log</span><span class="p">(</span>    <span class="s1">&#39;used_sys_memory: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">used_sys_memory</span><span class="o">/</span><span class="mi">1000000</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;        num_jobs_sys: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">max_job_sys</span><span class="p">),</span> <span class="n">path_log_file</span><span class="p">)</span>

        <span class="c1"># Define variables used for parallelization</span>
        <span class="n">num_gpu</span>  <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span><span class="p">()</span>
        <span class="n">num_jobs</span> <span class="o">=</span> <span class="n">max_job_gpu</span>                         <span class="k">if</span> <span class="n">max_job_gpu</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">max_job_gpu</span> <span class="c1"># Expected number of jobs</span>
        <span class="n">max_jobs</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span> <span class="n">max_job_sys</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">cpu_count</span><span class="p">()</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span> <span class="k">if</span> <span class="n">max_job_sys</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">max_job_sys</span> <span class="c1"># Limit for max number of jobs</span>

<span class="c1">##    Define CPU information, if GPU not used.</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">tlog</span><span class="o">.</span><span class="n">output_log</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">WARNING: Using CPU processing only!</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">path_log_file</span><span class="p">)</span>

        <span class="c1"># To skip this part, max_jobs_sys in params file to a fixed positive number.</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">max_job_sys</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">)</span> <span class="ow">or</span> <span class="n">still_test</span><span class="p">:</span>
            <span class="c1"># Define memory tracking variables</span>
            <span class="n">used_sys_memory</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">free_sys_memory</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">stop_tracking</span>   <span class="o">=</span> <span class="kc">False</span>
            <span class="c1"># Start Memory Tracking</span>
            <span class="n">thread_sys</span> <span class="o">=</span> <span class="n">threading</span><span class="o">.</span><span class="n">Thread</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="n">track_memory_usage_sys</span><span class="p">)</span>
            <span class="n">thread_sys</span><span class="o">.</span><span class="n">daemon</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">thread_sys</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
            <span class="n">tlog</span><span class="o">.</span><span class="n">output_log</span><span class="p">(</span><span class="s1">&#39;Getting free_sys_memory... &#39;</span><span class="p">,</span> <span class="n">path_log_file</span><span class="p">)</span>
            <span class="n">base_free_sys_memory</span> <span class="o">=</span> <span class="n">free_sys_memory</span>
            <span class="c1"># Wait for memory tracking to initialize</span>
            <span class="k">while</span> <span class="p">(</span><span class="n">base_free_sys_memory</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">):</span>
                <span class="n">base_free_sys_memory</span> <span class="o">=</span> <span class="n">free_sys_memory</span>
                <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>
            <span class="n">tlog</span><span class="o">.</span><span class="n">output_log</span><span class="p">(</span><span class="s1">&#39;free_sys_memory: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">free_sys_memory</span><span class="o">/</span><span class="mi">1000000</span><span class="p">),</span> <span class="n">path_log_file</span><span class="p">)</span>
            
            <span class="c1"># Run CPU test</span>
            <span class="n">target_args</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
            <span class="n">worker_test</span> <span class="o">=</span> <span class="n">Process</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="n">target_fcn</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">[</span><span class="o">*</span><span class="n">target_args</span><span class="p">])</span>
            <span class="n">worker_test</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
            <span class="n">worker_test</span><span class="o">.</span><span class="n">join</span><span class="p">()</span>
            <span class="n">stop_tracking</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)</span>
            <span class="c1"># Calculate number of jobs</span>
            <span class="k">if</span> <span class="n">max_mem_sys</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">max_mem_sys</span> <span class="o">=</span> <span class="n">base_free_sys_memory</span> <span class="o">*</span> <span class="n">max_mem_sys</span>
            <span class="k">elif</span> <span class="n">max_mem_sys</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">max_mem_sys</span> <span class="o">=</span> <span class="n">base_free_sys_memory</span>
            <span class="n">test_max_job_sys</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span> <span class="nb">int</span><span class="p">((</span><span class="n">max_mem_sys</span> <span class="o">*</span> <span class="mf">0.95</span><span class="p">)</span> <span class="o">/</span> <span class="n">used_sys_memory</span><span class="p">)</span> <span class="o">*</span> <span class="n">percent_memory</span><span class="p">)</span>
            <span class="n">max_job_sys</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span> <span class="n">max_job_sys</span><span class="p">,</span> <span class="n">test_max_job_sys</span><span class="p">)</span> <span class="k">if</span> <span class="n">max_job_sys</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">test_max_job_sys</span>
            <span class="n">tlog</span><span class="o">.</span><span class="n">output_log</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">used_sys_memory: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">used_sys_memory</span><span class="o">/</span><span class="mi">1000000</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;        num_jobs_sys: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">max_job_sys</span><span class="p">),</span> <span class="n">path_log_file</span><span class="p">)</span>
 
        <span class="n">num_gpu</span>  <span class="o">=</span> <span class="mi">1</span> <span class="c1"># Must equal 1 for later loops to iterate correctly</span>
        <span class="n">num_jobs</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">cpu_count</span><span class="p">()</span> <span class="o">-</span> <span class="mi">2</span>                        <span class="k">if</span> <span class="n">max_job_gpu</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">max_job_gpu</span> <span class="o">*</span> <span class="n">num_gpu</span> <span class="c1"># Expected number of jobs</span>
        <span class="n">max_jobs</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span> <span class="n">max_job_sys</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">cpu_count</span><span class="p">()</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span> <span class="k">if</span> <span class="n">max_job_sys</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">max_job_sys</span> <span class="c1"># Limit for max number of jobs</span>
    
    <span class="k">return</span> <span class="n">num_gpu</span><span class="p">,</span> <span class="n">num_jobs</span><span class="p">,</span> <span class="n">max_jobs</span></div>



<div class="viewcode-block" id="track_memory_usage_gpu"><a class="viewcode-back" href="../../../toast.kitchen.parallel.html#toast.kitchen.parallel.track_memory_usage_gpu">[docs]</a><span class="k">def</span> <span class="nf">track_memory_usage_gpu</span><span class="p">(</span> <span class="n">device</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;Function to track the maximum instantaneous GPU memory usage. This function uses global variables </span>
<span class="sd">    to communicaite instantaneous memory tracking values to any process which needs it.</span>
<span class="sd">    </span>
<span class="sd">    The available GPU memory at the beginning of tracking is saved in a global variable ``free_gpu_memory``</span>
<span class="sd">    The max consumed memory from the time this funciton is called is saved in a global variable ``used_gpu_memory``</span>

<span class="sd">    To stop tracking, set the global variable ``stop_tracking`` to ``True``</span>

<span class="sd">    Args:</span>
<span class="sd">        device (int): GPU Bus index to track</span>

<span class="sd">    Returns:</span>
<span class="sd">        None. Global variable ``free_gpu_memory`` is updated initially when first called and ``used_gpu_memory`` is updated continuously.</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="c1"># Update global variables that can also be seen by the parent function</span>
    <span class="k">global</span> <span class="n">used_gpu_memory</span><span class="p">,</span> <span class="n">free_gpu_memory</span><span class="p">,</span> <span class="n">stop_tracking</span>

    <span class="c1"># Use py3nvml to access nvidia-smi equivalent driver information</span>
    <span class="kn">from</span> <span class="nn">py3nvml.py3nvml</span> <span class="kn">import</span> <span class="n">nvmlInit</span><span class="p">,</span> <span class="n">nvmlDeviceGetHandleByIndex</span><span class="p">,</span> <span class="n">nvmlDeviceGetMemoryInfo</span>
    <span class="n">nvmlInit</span><span class="p">()</span>
    <span class="n">handle</span> <span class="o">=</span> <span class="n">nvmlDeviceGetHandleByIndex</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">meminfo_gpu</span> <span class="o">=</span> <span class="n">nvmlDeviceGetMemoryInfo</span><span class="p">(</span><span class="n">handle</span><span class="p">)</span>
    <span class="n">free_gpu_memory</span> <span class="o">=</span> <span class="n">meminfo_gpu</span><span class="o">.</span><span class="n">free</span>

    <span class="c1"># Continuously update the tracking variables until told to stop.</span>
    <span class="k">while</span><span class="p">(</span> <span class="ow">not</span><span class="p">(</span><span class="n">stop_tracking</span><span class="p">)):</span>
        <span class="n">meminfo_gpu</span> <span class="o">=</span> <span class="n">nvmlDeviceGetMemoryInfo</span><span class="p">(</span><span class="n">handle</span><span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">free_gpu_memory</span> <span class="o">-</span> <span class="n">meminfo_gpu</span><span class="o">.</span><span class="n">free</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">used_gpu_memory</span><span class="p">:</span>
            <span class="n">used_gpu_memory</span> <span class="o">=</span> <span class="n">free_gpu_memory</span> <span class="o">-</span> <span class="n">meminfo_gpu</span><span class="o">.</span><span class="n">free</span>
        <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span></div>



<div class="viewcode-block" id="track_memory_usage_sys"><a class="viewcode-back" href="../../../toast.kitchen.parallel.html#toast.kitchen.parallel.track_memory_usage_sys">[docs]</a><span class="k">def</span> <span class="nf">track_memory_usage_sys</span><span class="p">():</span>
    <span class="sd">&#39;&#39;&#39;Function to track the maximum instantaneous system memory usage. This function uses global variables </span>
<span class="sd">    to communicaite instantaneous memory tracking values to any process which needs it.</span>
<span class="sd">    </span>
<span class="sd">    The available system memory at the beginning of tracking is saved in a global variable ``free_sys_memory``</span>
<span class="sd">    The max consumed memory from the time this funciton is called is saved in a global variable ``used_sys_memory``</span>

<span class="sd">    To stop tracking, set the global variable ``stop_tracking`` to ``True``</span>

<span class="sd">    Args:</span>
<span class="sd">        None.</span>

<span class="sd">    Returns:</span>
<span class="sd">        None. Global variable ``free_sys_memory`` is updated initially when first called and ``used_sys_memory`` is updated continuously.</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="c1"># Update global variables that can also be seen by the parent function</span>
    <span class="k">global</span> <span class="n">used_sys_memory</span><span class="p">,</span> <span class="n">free_sys_memory</span><span class="p">,</span> <span class="n">stop_tracking</span>

    <span class="kn">from</span> <span class="nn">psutil</span> <span class="kn">import</span> <span class="n">virtual_memory</span>
    <span class="n">meminfo_sys</span> <span class="o">=</span> <span class="n">virtual_memory</span><span class="p">()</span>
    <span class="n">free_sys_memory</span> <span class="o">=</span> <span class="n">meminfo_sys</span><span class="o">.</span><span class="n">available</span>

    <span class="c1"># Continuously update the tracking variables until told to stop.</span>
    <span class="k">while</span><span class="p">(</span> <span class="ow">not</span><span class="p">(</span><span class="n">stop_tracking</span><span class="p">)):</span>
        <span class="n">meminfo_sys</span> <span class="o">=</span> <span class="n">virtual_memory</span><span class="p">()</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">free_sys_memory</span> <span class="o">-</span> <span class="n">meminfo_sys</span><span class="o">.</span><span class="n">available</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">used_sys_memory</span><span class="p">:</span>
            <span class="n">used_sys_memory</span> <span class="o">=</span> <span class="n">free_sys_memory</span> <span class="o">-</span> <span class="n">meminfo_sys</span><span class="o">.</span><span class="n">available</span>
        <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span></div>



<div class="viewcode-block" id="update_process_queue"><a class="viewcode-back" href="../../../toast.kitchen.parallel.html#toast.kitchen.parallel.update_process_queue">[docs]</a><span class="k">def</span> <span class="nf">update_process_queue</span><span class="p">(</span> <span class="n">process_queue</span><span class="p">,</span> <span class="n">content</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;Helper function to standardize the format of process updates in a process queue.</span>

<span class="sd">    Gets a dictionary from the passed queue and adds content to that dictionary with the </span>
<span class="sd">    current process ID as the dictionary key.</span>

<span class="sd">    Args:</span>
<span class="sd">        process_queue (multiprocessing queue): Queue where process updates can be stored</span>
<span class="sd">        content (str, or any):                 Value to store in the queue to indicate process status.</span>

<span class="sd">    Returns:</span>
<span class="sd">        None. Updates the passed process_queue.</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="c1"># The process queue is a dicitonary with the current process ID as the key, which maps to a list of update values</span>
    <span class="c1"># To update the process queue, get the dict, update the proper Process ID info, then put the dict back.</span>
    <span class="n">tracker_dict</span> <span class="o">=</span> <span class="n">process_queue</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
    <span class="n">tracker_dict</span><span class="p">[</span> <span class="nb">str</span><span class="p">(</span><span class="n">current_process</span><span class="p">()</span><span class="o">.</span><span class="n">pid</span><span class="p">)]</span> <span class="o">=</span> <span class="n">content</span>
    <span class="n">process_queue</span><span class="o">.</span><span class="n">put</span><span class="p">(</span> <span class="n">tracker_dict</span><span class="p">)</span></div>


<div class="viewcode-block" id="_worker_process"><a class="viewcode-back" href="../../../toast.kitchen.parallel.html#toast.kitchen.parallel._worker_process">[docs]</a><span class="k">def</span> <span class="nf">_worker_process</span><span class="p">(</span> <span class="n">target_fcn</span><span class="p">,</span> <span class="n">torch_device</span><span class="p">,</span> <span class="n">a_queue</span><span class="p">,</span> <span class="n">r_queue</span><span class="p">,</span> <span class="n">p_queue</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39; This function is what is run be each process to retrieve new arguments and store returned values.</span>
<span class="sd">    It is a helper function to be used only by :py:func:`~run_parallel`</span>
<span class="sd">    </span>
<span class="sd">    This function will limit each parallel execution to one process and one thread (via `torch.set_num_threads&lt;https://pytorch.org/docs/stable/generated/torch.set_num_threads.html#torch.set_num_threads&gt;`, to avoid overallocation of CPU cores, which will slow execution down dramatically.</span>

<span class="sd">    Note:</span>

<span class="sd">        Function arguments are automatically `copy.deepcopy()`&#39;ed after being retrieved from the queue and</span>
<span class="sd">        before being passed to the target function. This avoids the need to deepcopy parameters before </span>
<span class="sd">        placing in the queue, which can cause the queue to become excessively large and result in slowdowns </span>
<span class="sd">        in retrieving parameters. This scenario will lead to excessive `queue.Empty` exceptions as many</span>
<span class="sd">        processes try to access a slow queue simultaneously.</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="c1"># First, add this process to the process queue to allow for accurate process tracking.</span>
    <span class="n">update_process_queue</span><span class="p">(</span> <span class="n">p_queue</span><span class="p">,</span> <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="s1">&#39;STARTED&#39;</span><span class="p">])</span>

    <span class="c1"># Limit torch to only one parallelization thread, to avoid overallocation of CPU resources by all parallel threads</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">set_num_threads</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Each worker will infinitely retrieve and run train_parallel functions until there are no more fcn_args left to run.</span>
    <span class="n">queue_requests</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
        <span class="c1"># Get new function arguments to run.</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">update_process_queue</span><span class="p">(</span> <span class="n">p_queue</span><span class="p">,</span> <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="s1">&#39;GETTING ARGS&#39;</span><span class="p">])</span>
            <span class="n">fcn_args</span> <span class="o">=</span> <span class="n">a_queue</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">timeout</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="k">except</span> <span class="n">queue</span><span class="o">.</span><span class="n">Empty</span><span class="p">:</span>
            <span class="c1"># The queue may return empty if it collides with another process, so don&#39;t quit immediately.</span>
            <span class="c1"># If this happens more than 5 times, something is definitely wrong.</span>
            <span class="n">queue_requests</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="n">queue_requests</span> <span class="o">&gt;</span> <span class="mi">5</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">queue</span><span class="o">.</span><span class="n">Empty</span>
            <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">())</span> <span class="c1"># Wait a random time between 0 and 1 seconds</span>
            <span class="k">continue</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">e</span>

        <span class="n">update_process_queue</span><span class="p">(</span> <span class="n">p_queue</span><span class="p">,</span> <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="s1">&#39;EXTRACTING ARGS&#39;</span><span class="p">])</span>
        <span class="n">queue_requests</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="c1"># Get the next set of function arguments to run, then return the remaining function arguments to the queue.</span>
        <span class="k">if</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span> <span class="n">fcn_args</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">):</span>
            <span class="n">fcn_arg</span> <span class="o">=</span> <span class="n">fcn_args</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">a_queue</span><span class="o">.</span><span class="n">put</span><span class="p">(</span> <span class="n">fcn_args</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># There are no remaining function arguments to run. Update the process tracker to done, and return/terminate.</span>
            <span class="n">a_queue</span><span class="o">.</span><span class="n">put</span><span class="p">(</span> <span class="n">fcn_args</span><span class="p">)</span>
            <span class="n">update_process_queue</span><span class="p">(</span> <span class="n">p_queue</span><span class="p">,</span> <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="s1">&#39;DONE&#39;</span><span class="p">])</span>
            <span class="k">return</span>

        <span class="c1"># Copy the args to avoid potential memory leakage between processes</span>
        <span class="n">fcn_arg</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">fcn_arg</span><span class="p">)</span>
        <span class="c1"># Insert the GPU/torch_device used by this process into the function args</span>
        <span class="n">fcn_arg</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch_device</span>
        <span class="c1"># Exit if necessary</span>
        <span class="n">tterm</span><span class="o">.</span><span class="n">check_exit</span><span class="p">()</span>
        <span class="c1"># Update the process queue to accuratly track running processes</span>
        <span class="n">update_process_queue</span><span class="p">(</span> <span class="n">p_queue</span><span class="p">,</span> <span class="n">fcn_arg</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># Run the target function</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">target_fcn</span><span class="p">(</span> <span class="o">*</span><span class="n">fcn_arg</span><span class="p">)</span>

        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">update_process_queue</span><span class="p">(</span> <span class="n">p_queue</span><span class="p">,</span> <span class="p">[</span><span class="n">e</span><span class="p">,</span> <span class="s1">&#39;EXCEPTION RAISED&#39;</span><span class="p">])</span>
            <span class="k">raise</span> <span class="n">e</span>
        <span class="c1"># Update the process queue to show finished</span>
        <span class="n">update_process_queue</span><span class="p">(</span> <span class="n">p_queue</span><span class="p">,</span> <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="s1">&#39;FINISHED TRAIN FUNCTION&#39;</span><span class="p">])</span>
        <span class="c1"># Add the results to the results queue.</span>
        <span class="n">r_queue</span><span class="o">.</span><span class="n">put</span><span class="p">(</span> <span class="n">outputs</span><span class="p">)</span>
        <span class="n">update_process_queue</span><span class="p">(</span> <span class="n">p_queue</span><span class="p">,</span> <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="s1">&#39;SAVED RESULTS&#39;</span><span class="p">])</span>

        <span class="k">if</span> <span class="n">tterm</span><span class="o">.</span><span class="n">check_finish</span><span class="p">():</span>
            <span class="k">return</span></div>



<div class="viewcode-block" id="_worker_error"><a class="viewcode-back" href="../../../toast.kitchen.parallel.html#toast.kitchen.parallel._worker_error">[docs]</a><span class="k">def</span> <span class="nf">_worker_error</span><span class="p">(</span> <span class="n">error_instance</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;This function is the callback funciton if an asynchronous worker raises an error. </span>
<span class="sd">    It simply prints the error to stdout.</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="c1"># Handle worker errors gracefully by alerting the user and printing the error type and instance.</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">WORKER ERROR OCCURED</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">error_instance</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">error_instance</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="p">)</span></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, Cybernetic Implantable Devices.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>